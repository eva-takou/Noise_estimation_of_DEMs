{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d52f5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/evatakou/noise_est')\n",
    "import stim\n",
    "import numpy as np\n",
    "import pymatching\n",
    "from pymatching import Matching\n",
    "import xarray as xr\n",
    "from circuit_SC_phen import *\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38722d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sims.surface_code_bare_ancilla.construct_dem import get_measurement_data,project_data_meas,get_initial_state,surface_code_DEM, get_defects\n",
    "from sims.surface_code_bare_ancilla.estimation_funcs_surface_code import *\n",
    "from utilities.general_utils import avg_vi,avg_vivj\n",
    "from utilities.utils_for_decoding import decode_both_dems_same_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e71a3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DEM(distance,num_rounds,num_shots,p_data,p_anc,std):\n",
    "\n",
    "    num_ancilla   = distance*(distance-1)\n",
    "    \n",
    "    circuit       = planar_surface_code_circuit_X_memory(distance,num_rounds,p_data,p_anc,std)\n",
    "\n",
    "    defects_matrix,data_qubit_meas = get_defects(circuit,distance,num_shots,num_rounds)\n",
    "    vi_mean                        = avg_vi(defects_matrix)\n",
    "    pij_time    = estimate_time_edge_probs_alt_V2(num_rounds,num_ancilla,defects_matrix,vi_mean)\n",
    "    \n",
    "\n",
    "    pij_bulk,pij_bd = estimate_bulk_and_bd_edge_probs_alt_Final(num_rounds,num_ancilla,distance,defects_matrix,pij_time,vi_mean)\n",
    "\n",
    "    \n",
    "    my_DEM = surface_code_DEM(pij_bulk,pij_bd,pij_time,circuit.detector_error_model(flatten_loops=True))\n",
    "\n",
    "    return my_DEM,circuit\n",
    "\n",
    "std=0\n",
    "distance   = 9\n",
    "num_rounds = 9\n",
    "num_shots  = 10**6\n",
    "p_data     = 0.1\n",
    "p_anc      = 0.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb37f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_both_dems_same_data(reconstructed_DEM:stim.DetectorErrorModel,circuit:stim.Circuit, detector_error_model: stim.DetectorErrorModel ,num_shots:int):\n",
    "    '''\n",
    "    Decode stim's DEM obtained from a circuit and a reconstructed DEM using MWPM, and on the same data.\n",
    "\n",
    "    Inputs: \n",
    "        my_DEM:    Reconstructed detector error model\n",
    "        circuit:   The true stim circuit (w/ variations on data/ancilla qubits)\n",
    "        detector_error_model: stim's detector error model for the case of all error rates of data being equal to p, and all error rates of ancilla being equal to q\n",
    "        num_shots: # of shots to use to decode\n",
    "    Output:\n",
    "        num_errors_est:    Total # of logical errors obtained by decoding the reconstructed DEM\n",
    "        num_errors_stim:   Total # of logical errors obtained by decoding stim's DEM\n",
    "    '''\n",
    "    # Sample the circuit.\n",
    "    sampler = circuit.compile_detector_sampler()\n",
    "    detection_events, observable_flips = sampler.sample(num_shots, separate_observables=True)\n",
    "\n",
    "    # Configure a decoder using the circuit.\n",
    "    # detector_error_model = circuit.detector_error_model(flatten_loops=True) \n",
    "    matcher              = pymatching.Matching.from_detector_error_model(detector_error_model)\n",
    "\n",
    "    # Run the decoder.\n",
    "    predictions = matcher.decode_batch(detection_events)\n",
    "\n",
    "    # Count the mistakes.\n",
    "    num_errors_stim =   np.sum(~np.all(observable_flips == predictions, axis=1))  \n",
    "\n",
    "    #Now do the same for my model.\n",
    "\n",
    "    matcher     = pymatching.Matching.from_detector_error_model(reconstructed_DEM)\n",
    "    predictions = matcher.decode_batch(detection_events) #use same detection events\n",
    "\n",
    "    num_errors_est =   np.sum(~np.all(observable_flips == predictions, axis=1))  \n",
    "\n",
    "    return num_errors_est,num_errors_stim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6b755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=0.050, q=0.050 -> stim: 0.1101, our_DEM: 0.0968\n",
      "p=0.050, q=0.056 -> stim: 0.1029, our_DEM: 0.0972\n",
      "p=0.050, q=0.061 -> stim: 0.1034, our_DEM: 0.0968\n",
      "p=0.050, q=0.067 -> stim: 0.1042, our_DEM: 0.0978\n",
      "p=0.050, q=0.090 -> stim: 0.1073, our_DEM: 0.1020\n",
      "p=0.050, q=0.079 -> stim: 0.1060, our_DEM: 0.1002\n",
      "p=0.050, q=0.073 -> stim: 0.1051, our_DEM: 0.0990\n",
      "p=0.050, q=0.084 -> stim: 0.1069, our_DEM: 0.1013\n",
      "p=0.050, q=0.096 -> stim: 0.1086, our_DEM: 0.1028\n",
      "p=0.050, q=0.101 -> stim: 0.1097, our_DEM: 0.1040\n",
      "p=0.050, q=0.107 -> stim: 0.1104, our_DEM: 0.1050\n",
      "p=0.050, q=0.113 -> stim: 0.1112, our_DEM: 0.1059\n",
      "p=0.050, q=0.119 -> stim: 0.1119, our_DEM: 0.1068\n",
      "p=0.050, q=0.124 -> stim: 0.1133, our_DEM: 0.1078\n",
      "p=0.050, q=0.130 -> stim: 0.1137, our_DEM: 0.1090\n",
      "p=0.056, q=0.050 -> stim: 0.1281, our_DEM: 0.1132\n",
      "p=0.056, q=0.056 -> stim: 0.1309, our_DEM: 0.1151\n",
      "p=0.056, q=0.061 -> stim: 0.1214, our_DEM: 0.1150\n",
      "p=0.056, q=0.067 -> stim: 0.1226, our_DEM: 0.1150\n",
      "p=0.056, q=0.073 -> stim: 0.1231, our_DEM: 0.1161\n",
      "p=0.056, q=0.079 -> stim: 0.1239, our_DEM: 0.1174\n",
      "p=0.056, q=0.090 -> stim: 0.1257, our_DEM: 0.1195\n",
      "p=0.056, q=0.084 -> stim: 0.1248, our_DEM: 0.1183\n",
      "p=0.056, q=0.096 -> stim: 0.1266, our_DEM: 0.1207\n",
      "p=0.056, q=0.101 -> stim: 0.1280, our_DEM: 0.1216\n",
      "p=0.056, q=0.107 -> stim: 0.1290, our_DEM: 0.1225\n",
      "p=0.056, q=0.113 -> stim: 0.1296, our_DEM: 0.1236\n",
      "p=0.056, q=0.119 -> stim: 0.1306, our_DEM: 0.1250\n",
      "p=0.056, q=0.124 -> stim: 0.1322, our_DEM: 0.1259\n",
      "p=0.056, q=0.130 -> stim: 0.1320, our_DEM: 0.1265\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def get_logical_error_per_p_and_q(std_in, distance, num_shots, num_vals, n_jobs=-1):\n",
    "    \n",
    "    prange_data = np.linspace(5e-2, 0.13, num_vals)\n",
    "    prange_ancilla = np.linspace(5e-2, 0.13, num_vals)\n",
    "\n",
    "    # prange_data    = np.linspace(1e-2,0.1,num_vals) #(Values used for d=5 in appendix)\n",
    "    # prange_ancilla = np.linspace(1e-2,0.1,num_vals)\n",
    "    num_rounds = distance\n",
    "    \n",
    "\n",
    "    def evaluate_pair(p, q):\n",
    "        my_DEM, circuit_true = get_DEM(distance, num_rounds, num_shots, p, q, std_in)\n",
    "        circuit2 = planar_surface_code_circuit_X_memory(distance, num_rounds, p, q, std=0)\n",
    "        stims_DEM = circuit2.detector_error_model(flatten_loops=True)\n",
    "        num_errors_my_DEM, num_errors_stim = decode_both_dems_same_data(my_DEM, circuit_true, stims_DEM, num_shots)\n",
    "\n",
    "        print(f\"p={p:.3f}, q={q:.3f} -> stim: {num_errors_stim / num_shots:.4f}, our_DEM: {num_errors_my_DEM / num_shots:.4f}\")\n",
    "\n",
    "        return num_errors_my_DEM / num_shots, num_errors_stim / num_shots\n",
    "\n",
    "    all_LE_mine = []\n",
    "    all_LE_stim = []\n",
    "\n",
    "    for p in prange_data:\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(evaluate_pair)(p, q) for q in prange_ancilla\n",
    "        )\n",
    "\n",
    "        LE_mine_row, LE_stim_row = zip(*results)\n",
    "        all_LE_mine.append(LE_mine_row)\n",
    "        all_LE_stim.append(LE_stim_row)\n",
    "\n",
    "    return all_LE_mine, all_LE_stim, prange_data, prange_ancilla\n",
    "\n",
    "\n",
    "distance                                           = 3\n",
    "std                                                = 5*10**(-3)\n",
    "num_shots                                          = 5*10**6\n",
    "num_vals                                           = 15\n",
    "all_LE_mine,all_LE_stim,prange_data,prange_ancilla = get_logical_error_per_p_and_q(std,distance,num_shots,num_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28874999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To store the data:\n",
    "\n",
    "# with open(\"stims_for_5_10_minus_3_and_N_5_10_6_d_5_r_5.txt\", \"w\") as file:\n",
    "#     file.write(str(all_LE_stim))\n",
    "# with open(\"mine_for_5_10_minus_3_and_N_5_10_6_d_5_r_5.txt\", \"w\") as file:\n",
    "#     file.write(str(all_LE_mine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement_factor = []\n",
    "\n",
    " \n",
    "for k in range(len(prange_data)):\n",
    "    \n",
    "    temp1 = all_LE_mine[k]\n",
    "    temp2 = all_LE_stim[k]\n",
    "    temp  = []\n",
    "\n",
    "    for l in range(len(prange_ancilla)):\n",
    "\n",
    "        # temp.append( abs(temp1[l]-temp2[l])/temp2[l]*100 )  #(xf-x)/x %\n",
    "        temp.append(temp2[l]/temp1[l]) \n",
    "\n",
    "        if temp2[l]<temp1[l]:\n",
    "            print(\"stim performs better for (p,q) =\",(prange_data[k],prange_ancilla[l]))\n",
    "            print(\"stim:\",temp2[l],\"ours:\",temp1[l])\n",
    "            \n",
    "\n",
    "    improvement_factor.append(temp)\n",
    "\n",
    "print(max(max(improvement_factor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy import *\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 17})\n",
    "plt.rcParams[\"font.family\"] = \"Microsoft Sans Serif\"   \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "X, Y    = np.meshgrid(prange_data, prange_ancilla)\n",
    "Z       = np.array(improvement_factor)\n",
    "\n",
    "# 1.1152711081196527: max value found for 10**(-3) std\n",
    "# 1.012510355791058: min value found for 10**(-3) std\n",
    "\n",
    "plt.pcolormesh(X, Y, Z,vmin=1.012510355791058, vmax=1.1152711081196527 , cmap=cm.berlin,linewidth=0, antialiased=False,snap=False)#,shading='gouraud'\n",
    "\n",
    "\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"$p$\")\n",
    "plt.ylabel(\"$q$\")\n",
    "\n",
    "# fig.savefig(\"Improvement_factor_d_5_r_5_N_5_10__6__5_10_minus_3.pdf\",bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noise_est",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
